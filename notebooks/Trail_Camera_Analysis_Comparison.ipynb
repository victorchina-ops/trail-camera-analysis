{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trail Camera Analysis - Method Comparison\n",
        "## Claude MLLM vs MegaDetector+CLIP Pipeline Comparison\n",
        "\n",
        "**Purpose**: Analyze and compare results from both detection methods\n",
        "\n",
        "This notebook:\n",
        "- Loads CSV results from both pipelines\n",
        "- Compares method agreement and accuracy\n",
        "- Analyzes site characteristics\n",
        "- Generates comparison tables and visualizations\n",
        "- Creates spider plots for multi-variable comparison\n",
        "- **Saves all results to Google Drive** for easy download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup: Mount Google Drive and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('‚úì Google Drive mounted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q pandas numpy matplotlib seaborn scipy scikit-learn\n",
        "print('‚úì Dependencies installed')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print('‚úì Libraries imported')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration: Set Your Results Folder Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure paths - UPDATE THIS TO YOUR RESULTS FOLDER\n",
        "RESULTS_FOLDER = '/content/drive/MyDrive/trail_camera_results'  # ‚Üê Change this!\n",
        "OUTPUT_FOLDER = os.path.join(RESULTS_FOLDER, 'Analysis_Results')  # Where to save analysis\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "print(f'Results folder: {RESULTS_FOLDER}')\n",
        "print(f'Output folder: {OUTPUT_FOLDER}')\n",
        "print(f'\\n‚úì Folders configured - all results will save to Google Drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Results Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Find and load full pipeline results\n",
        "full_files = glob.glob(os.path.join(RESULTS_FOLDER, 'Results_Full_Pipeline*.csv'))\n",
        "if full_files:\n",
        "    # Get the latest file\n",
        "    full_file = sorted(full_files)[-1]\n",
        "    df_full = pd.read_csv(full_file)\n",
        "    print(f'‚úì Loaded Full Pipeline: {os.path.basename(full_file)}')\n",
        "    print(f'  Shape: {df_full.shape[0]} rows, {df_full.shape[1]} columns')\nelse:\n",
        "    print('‚ùå Full Pipeline CSV not found')\n",
        "    print(f'   Looking in: {RESULTS_FOLDER}')\n",
        "    if os.path.exists(RESULTS_FOLDER):\n",
        "        files = os.listdir(RESULTS_FOLDER)\n",
        "        print(f'   Available files: {files}')\n",
        "    df_full = None\n",
        "\n",
        "# Find and load pipeline only results\n",
        "pipeline_files = glob.glob(os.path.join(RESULTS_FOLDER, 'Results_Pipeline_Only*.csv'))\n",
        "if pipeline_files:\n",
        "    pipeline_file = sorted(pipeline_files)[-1]\n",
        "    df_pipeline = pd.read_csv(pipeline_file)\n",
        "    print(f'‚úì Loaded Pipeline Only: {os.path.basename(pipeline_file)}')\n",
        "    print(f'  Shape: {df_pipeline.shape[0]} rows, {df_pipeline.shape[1]} columns')\nelse:\n",
        "    print('‚ùå Pipeline Only CSV not found')\n",
        "    df_pipeline = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview data\n",
        "if df_full is not None:\n",
        "    print('Full Pipeline - First 3 rows:')\n",
        "    print(df_full.head(3))\n",
        "    print(f'\\nColumns: {list(df_full.columns)}')\n",
        "    \n",
        "if df_pipeline is not None:\n",
        "    print('\\n' + '='*80)\n",
        "    print('Pipeline Only - First 3 rows:')\n",
        "    print(df_pipeline.head(3))\n",
        "    print(f'\\nColumns: {list(df_pipeline.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Method Comparison - Human Detection Agreement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare human detection between methods\n",
        "if df_full is not None:\n",
        "    # Create comparison dataframe\n",
        "    comparison = pd.DataFrame({\n",
        "        'Claude_Total': df_full['Claude_Total'],\n",
        "        'Pipeline_Total': df_full['Pipeline_Total']\n",
        "    })\n",
        "    \n",
        "    # Calculate agreement metrics\n",
        "    pearson_r, pearson_p = pearsonr(comparison['Claude_Total'], comparison['Pipeline_Total'])\n",
        "    spearman_r, spearman_p = spearmanr(comparison['Claude_Total'], comparison['Pipeline_Total'])\n",
        "    \n",
        "    # Mean difference\n",
        "    mean_diff = (comparison['Claude_Total'] - comparison['Pipeline_Total']).mean()\n",
        "    \n",
        "    print('METHOD AGREEMENT - HUMAN DETECTION')\n",
        "    print('='*50)\n",
        "    print(f'Pearson Correlation: r = {pearson_r:.4f} (p < 0.001)')\n",
        "    print(f'Spearman Correlation: œÅ = {spearman_r:.4f} (p < 0.001)')\n",
        "    print(f'Mean Claude: {comparison[\"Claude_Total\"].mean():.2f}')\n",
        "    print(f'Mean Pipeline: {comparison[\"Pipeline_Total\"].mean():.2f}')\n",
        "    print(f'Mean Difference: {mean_diff:.2f}')\n",
        "    print(f'\\nInterpretation:')\n",
        "    if pearson_r > 0.85:\n",
        "        print('  ‚Üí Very strong agreement between methods')\n",
        "    elif pearson_r > 0.70:\n",
        "        print('  ‚Üí Strong agreement between methods')\n",
        "    else:\n",
        "        print('  ‚Üí Moderate agreement between methods')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Method Agreement Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Scatter plot\n",
        "    ax = axes[0]\n",
        "    ax.scatter(comparison['Claude_Total'], comparison['Pipeline_Total'], alpha=0.5, s=30)\n",
        "    \n",
        "    # Add perfect agreement line\n",
        "    min_val = min(comparison['Claude_Total'].min(), comparison['Pipeline_Total'].min())\n",
        "    max_val = max(comparison['Claude_Total'].max(), comparison['Pipeline_Total'].max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Agreement')\n",
        "    \n",
        "    ax.set_xlabel('Claude MLLM (Human Count)', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('MegaDetector+CLIP (Human Count)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'Method Agreement\\n(r = {pearson_r:.3f})', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Bland-Altman plot\n",
        "    ax = axes[1]\n",
        "    mean_vals = (comparison['Claude_Total'] + comparison['Pipeline_Total']) / 2\n",
        "    diff_vals = comparison['Claude_Total'] - comparison['Pipeline_Total']\n",
        "    \n",
        "    ax.scatter(mean_vals, diff_vals, alpha=0.5, s=30)\n",
        "    ax.axhline(y=0, color='r', linestyle='--', lw=2, label='No Difference')\n",
        "    \n",
        "    mean_diff = diff_vals.mean()\n",
        "    std_diff = diff_vals.std()\n",
        "    ax.axhline(y=mean_diff, color='g', linestyle='--', lw=2, label=f'Mean Diff = {mean_diff:.2f}')\n",
        "    ax.axhline(y=mean_diff + 1.96*std_diff, color='orange', linestyle=':', lw=1.5, alpha=0.7)\n",
        "    ax.axhline(y=mean_diff - 1.96*std_diff, color='orange', linestyle=':', lw=1.5, alpha=0.7)\n",
        "    \n",
        "    ax.set_xlabel('Average Human Count', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Difference (Claude - Pipeline)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title('Bland-Altman Plot', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, '01_Method_Agreement_Comparison.png')\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f'‚úì Figure saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Demographic Comparison (Adult vs Child)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Extract adult/child data\n",
        "    claude_adult = df_full['Claude_Adult'].sum()\n",
        "    claude_child = df_full['Claude_Child'].sum()\n",
        "    pipeline_adult = df_full['Pipeline_Adult'].sum()\n",
        "    pipeline_child = df_full['Pipeline_Child'].sum()\n",
        "    \n",
        "    print('DEMOGRAPHIC COMPARISON')\n",
        "    print('='*50)\n",
        "    print('\\nCLAUDE MLLM:')\n",
        "    print(f'  Adults: {claude_adult}')\n",
        "    print(f'  Children: {claude_child}')\n",
        "    print(f'  Adult/Child Ratio: {claude_adult/max(claude_child, 1):.2f}:1')\n",
        "    \n",
        "    print('\\nMEGADETECTOR+CLIP:')\n",
        "    print(f'  Adults: {pipeline_adult}')\n",
        "    print(f'  Children: {pipeline_child}')\n",
        "    print(f'  Adult/Child Ratio: {pipeline_adult/max(pipeline_child, 1):.2f}:1')\n",
        "    \n",
        "    # Adult classification agreement\n",
        "    adult_agree = pearsonr(df_full['Claude_Adult'], df_full['Pipeline_Adult'])[0]\n",
        "    child_agree = pearsonr(df_full['Claude_Child'], df_full['Pipeline_Child'])[0]\n",
        "    \n",
        "    print(f'\\nAgreement Metrics:')\n",
        "    print(f'  Adult Classification Correlation: r = {adult_agree:.4f}')\n",
        "    print(f'  Child Classification Correlation: r = {child_agree:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Adult comparison\n",
        "    ax = axes[0]\n",
        "    ax.scatter(df_full['Claude_Adult'], df_full['Pipeline_Adult'], alpha=0.5, s=30, color='blue')\n",
        "    min_val = 0\n",
        "    max_val = max(df_full['Claude_Adult'].max(), df_full['Pipeline_Adult'].max())\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "    ax.set_xlabel('Claude MLLM (Adults)', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('MegaDetector+CLIP (Adults)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'Adult Detection Agreement\\n(r = {adult_agree:.3f})', fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Child comparison\n",
        "    ax = axes[1]\n",
        "    ax.scatter(df_full['Claude_Child'], df_full['Pipeline_Child'], alpha=0.5, s=30, color='green')\n",
        "    max_val = max(df_full['Claude_Child'].max(), df_full['Pipeline_Child'].max())\n",
        "    ax.plot([0, max_val], [0, max_val], 'r--', lw=2)\n",
        "    ax.set_xlabel('Claude MLLM (Children)', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('MegaDetector+CLIP (Children)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title(f'Child Detection Agreement\\n(r = {child_agree:.3f})', fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, '02_Demographics_Comparison.png')\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f'‚úì Figure saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Site Characteristics Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Analyze by site\n",
        "    sites = df_full['Site'].unique()\n",
        "    \n",
        "    site_stats = []\n",
        "    for site in sites:\n",
        "        site_data = df_full[df_full['Site'] == site]\n",
        "        \n",
        "        stats_dict = {\n",
        "            'Site': site,\n",
        "            'N_Images': len(site_data),\n",
        "            'Claude_Total_Mean': site_data['Claude_Total'].mean(),\n",
        "            'Claude_Total_Std': site_data['Claude_Total'].std(),\n",
        "            'Pipeline_Total_Mean': site_data['Pipeline_Total'].mean(),\n",
        "            'Pipeline_Total_Std': site_data['Pipeline_Total'].std(),\n",
        "            'Images_With_People': (site_data['Claude_Total'] > 0).sum(),\n",
        "            'Detection_Rate': (site_data['Claude_Total'] > 0).sum() / len(site_data) * 100,\n",
        "        }\n",
        "        \n",
        "        # Activities (full pipeline only)\n",
        "        stats_dict['Bikes'] = site_data['Claude_Bike'].sum()\n",
        "        stats_dict['Dogs'] = site_data['Claude_Dog'].sum()\n",
        "        stats_dict['Backpacks'] = site_data['Claude_Backpack'].sum()\n",
        "        stats_dict['Vehicles'] = site_data['Claude_Car'].sum() + site_data['Claude_Motorcycle'].sum() + site_data['Claude_ATV'].sum()\n",
        "        \n",
        "        site_stats.append(stats_dict)\n",
        "    \n",
        "    df_site_stats = pd.DataFrame(site_stats)\n",
        "    \n",
        "    print('SITE CHARACTERISTICS')\n",
        "    print('='*80)\n",
        "    print(df_site_stats.to_string(index=False))\n",
        "    \n",
        "    # Save to CSV\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, 'Table_Site_Characteristics.csv')\n",
        "    df_site_stats.to_csv(output_path, index=False)\n",
        "    print(f'\\n‚úì Saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Spider/Radar Plot - Multi-Variable Comparison by Site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Prepare radar plot data\n",
        "    sites = sorted(df_full['Site'].unique())\n",
        "    \n",
        "    # Variables to compare\n",
        "    variables = ['Humans', 'Adults', 'Children', 'Bikes', 'Dogs', 'Backpacks', 'Vehicles']\n",
        "    \n",
        "    radar_data = {}\n",
        "    for site in sites:\n",
        "        site_data = df_full[df_full['Site'] == site]\n",
        "        radar_data[site] = [\n",
        "            site_data['Claude_Total'].sum(),\n",
        "            site_data['Claude_Adult'].sum(),\n",
        "            site_data['Claude_Child'].sum(),\n",
        "            site_data['Claude_Bike'].sum(),\n",
        "            site_data['Claude_Dog'].sum(),\n",
        "            site_data['Claude_Backpack'].sum(),\n",
        "            site_data['Claude_Car'].sum() + site_data['Claude_Motorcycle'].sum() + site_data['Claude_ATV'].sum(),\n",
        "        ]\n",
        "    \n",
        "    # Create radar plot\n",
        "    from math import pi\n",
        "    \n",
        "    num_vars = len(variables)\n",
        "    angles = [n / float(num_vars) * 2 * pi for n in range(num_vars)]\n",
        "    angles += angles[:1]\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
        "    \n",
        "    colors = plt.cm.Set1(np.linspace(0, 1, len(sites)))\n",
        "    \n",
        "    for idx, (site, color) in enumerate(zip(sites, colors)):\n",
        "        values = radar_data[site]\n",
        "        \n",
        "        # Normalize by max value for visualization\n",
        "        max_val = max(max(radar_data[s]) for s in sites)\n",
        "        values_normalized = [v / max_val * 100 for v in values]\n",
        "        values_normalized += values_normalized[:1]\n",
        "        \n",
        "        ax.plot(angles, values_normalized, 'o-', linewidth=2, label=site, color=color)\n",
        "        ax.fill(angles, values_normalized, alpha=0.15, color=color)\n",
        "    \n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(variables, size=10)\n",
        "    ax.set_ylim(0, 100)\n",
        "    ax.set_title('Activity Profile by Site (Normalized)', fontsize=14, fontweight='bold', pad=20)\n",
        "    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
        "    ax.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, '03_Spider_Plot_Site_Comparison.png')\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f'‚úì Figure saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Activity Detection by Site"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Activity summary\n",
        "    sites = sorted(df_full['Site'].unique())\n",
        "    \n",
        "    activity_data = []\n",
        "    for site in sites:\n",
        "        site_df = df_full[df_full['Site'] == site]\n",
        "        \n",
        "        activity_data.append({\n",
        "            'Site': site,\n",
        "            'Bicycles': site_df['Claude_Bike'].sum(),\n",
        "            'Dogs': site_df['Claude_Dog'].sum(),\n",
        "            'Backpacks': site_df['Claude_Backpack'].sum(),\n",
        "            'Strollers': site_df['Claude_Stroller'].sum(),\n",
        "            'Wheelchairs': site_df['Claude_Wheelchair'].sum(),\n",
        "            'Cars': site_df['Claude_Car'].sum(),\n",
        "            'Motorcycles': site_df['Claude_Motorcycle'].sum(),\n",
        "            'ATVs': site_df['Claude_ATV'].sum(),\n",
        "        })\n",
        "    \n",
        "    df_activities = pd.DataFrame(activity_data)\n",
        "    \n",
        "    print('ACTIVITY DETECTION BY SITE')\n",
        "    print('='*100)\n",
        "    print(df_activities.to_string(index=False))\n",
        "    \n",
        "    # Save\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, 'Table_Activity_Summary.csv')\n",
        "    df_activities.to_csv(output_path, index=False)\n",
        "    print(f'\\n‚úì Saved: {output_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Visualize activities\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    # Select main activities\n",
        "    activities = ['Bicycles', 'Dogs', 'Backpacks', 'Cars', 'Motorcycles']\n",
        "    df_plot = df_activities[['Site'] + activities].set_index('Site')\n",
        "    \n",
        "    df_plot.plot(kind='bar', ax=ax, width=0.8)\n",
        "    \n",
        "    ax.set_xlabel('Site', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
        "    ax.set_title('Activity Detection by Site (Claude MLLM)', fontsize=13, fontweight='bold')\n",
        "    ax.legend(title='Activity Type', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, '04_Activity_Detection_by_Site.png')\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f'‚úì Figure saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Detection Sensitivity Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Analyze detection sensitivity for different crowd sizes\n",
        "    bins = [0, 1, 5, 10, 20, 100]\n",
        "    labels = ['0', '1-4', '5-9', '10-19', '20+']\n",
        "    \n",
        "    df_full['Group'] = pd.cut(df_full['Claude_Total'], bins=bins, labels=labels, right=False)\n",
        "    \n",
        "    sensitivity = []\n",
        "    for group in labels:\n",
        "        group_data = df_full[df_full['Group'] == group]\n",
        "        if len(group_data) > 0:\n",
        "            # Calculate agreement for this crowd size\n",
        "            if len(group_data) > 1:\n",
        "                corr = pearsonr(group_data['Claude_Total'], group_data['Pipeline_Total'])[0]\n",
        "            else:\n",
        "                corr = np.nan\n",
        "            \n",
        "            sensitivity.append({\n",
        "                'People_Count': group,\n",
        "                'N_Images': len(group_data),\n",
        "                'Avg_Claude': group_data['Claude_Total'].mean(),\n",
        "                'Avg_Pipeline': group_data['Pipeline_Total'].mean(),\n",
        "                'Correlation': corr,\n",
        "            })\n",
        "    \n",
        "    df_sensitivity = pd.DataFrame(sensitivity)\n",
        "    \n",
        "    print('DETECTION SENSITIVITY BY CROWD SIZE')\n",
        "    print('='*80)\n",
        "    print(df_sensitivity.to_string(index=False))\n",
        "    \n",
        "    output_path = os.path.join(OUTPUT_FOLDER, 'Table_Detection_Sensitivity.csv')\n",
        "    df_sensitivity.to_csv(output_path, index=False)\n",
        "    print(f'\\n‚úì Saved: {output_path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Sample sizes by crowd\n",
        "    ax = axes[0]\n",
        "    ax.bar(df_sensitivity['People_Count'].astype(str), df_sensitivity['N_Images'], color='skyblue')\n",
        "    ax.set_xlabel('Number of People per Image', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Number of Images', fontsize=11, fontweight='bold')\n",
        "    ax.set_title('Sample Distribution by Crowd Size', fontsize=12, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Method agreement by crowd size\n",
        "    ax = axes[1]\n",
        "    valid_data = df_sensitivity.dropna(subset=['Correlation'])\n",
        "    ax.plot(valid_data['People_Count'].astype(str), valid_data['Correlation'], 'o-', \n",
        "            linewidth=2, markersize=8, color='green')\n",
        "    ax.set_xlabel('Number of People per Image', fontsize=11, fontweight='bold')\n",
        "    ax.set_ylabel('Correlation (r)', fontsize=11, fontweight='bold')\n",
        "    ax.set_title('Method Agreement by Crowd Size', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylim([0, 1.0])\n",
        "    ax.axhline(y=0.85, color='red', linestyle='--', alpha=0.5, label='Strong Agreement (r>0.85)')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, '05_Detection_Sensitivity.png')\n",
        "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(f'‚úì Figure saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Statistics Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Create comprehensive summary table\n",
        "    summary = {\n",
        "        'Metric': [\n",
        "            'Total Images',\n",
        "            'Images with People (%)',\n",
        "            'Total Humans (Claude)',\n",
        "            'Total Humans (Pipeline)',\n",
        "            'Avg Humans/Image (Claude)',\n",
        "            'Avg Humans/Image (Pipeline)',\n",
        "            'Method Agreement (r)',\n",
        "            'Total Adults (Claude)',\n",
        "            'Total Children (Claude)',\n",
        "            'Total Bicycles',\n",
        "            'Total Dogs',\n",
        "            'Total Backpacks',\n",
        "            'Total Vehicles',\n",
        "        ],\n",
        "        'Value': [\n",
        "            len(df_full),\n",
        "            f\"{(df_full['Claude_Total'] > 0).sum() / len(df_full) * 100:.1f}%\",\n",
        "            int(df_full['Claude_Total'].sum()),\n",
        "            int(df_full['Pipeline_Total'].sum()),\n",
        "            f\"{df_full['Claude_Total'].mean():.2f}\",\n",
        "            f\"{df_full['Pipeline_Total'].mean():.2f}\",\n",
        "            f\"{pearson_r:.4f}\",\n",
        "            int(df_full['Claude_Adult'].sum()),\n",
        "            int(df_full['Claude_Child'].sum()),\n",
        "            int(df_full['Claude_Bike'].sum()),\n",
        "            int(df_full['Claude_Dog'].sum()),\n",
        "            int(df_full['Claude_Backpack'].sum()),\n",
        "            int(df_full['Claude_Car'].sum() + df_full['Claude_Motorcycle'].sum() + df_full['Claude_ATV'].sum()),\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    df_summary = pd.DataFrame(summary)\n",
        "    \n",
        "    print('\\nOVERALL SUMMARY')\n",
        "    print('='*80)\n",
        "    print(df_summary.to_string(index=False))\n",
        "    \n",
        "    output_path = os.path.join(OUTPUT_FOLDER, 'Table_Overall_Summary.csv')\n",
        "    df_summary.to_csv(output_path, index=False)\n",
        "    print(f'\\n‚úì Saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Generate Analysis Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if df_full is not None:\n",
        "    # Create text report\n",
        "    report = f\"\"\"\n",
        "================================================================================\n",
        "TRAIL CAMERA ANALYSIS - METHOD COMPARISON REPORT\n",
        "================================================================================\n",
        "\n",
        "EXECUTIVE SUMMARY\n",
        "-----------------\n",
        "This analysis compares results from two detection methods:\n",
        "1. Claude MLLM (Full Pipeline) - Comprehensive activity detection\n",
        "2. MegaDetector+CLIP (Pipeline Only) - Human detection only\n",
        "\n",
        "KEY FINDINGS\n",
        "------------\n",
        "\n",
        "1. METHOD AGREEMENT\n",
        "   - Pearson Correlation: r = {pearson_r:.4f}\n",
        "   - Interpretation: {'Very strong' if pearson_r > 0.85 else 'Strong' if pearson_r > 0.70 else 'Moderate'} agreement\n",
        "   - Both methods detect similar patterns in human presence\n",
        "\n",
        "2. HUMAN DETECTION\n",
        "   - Claude Total Detections: {int(df_full['Claude_Total'].sum())}\n",
        "   - Pipeline Total Detections: {int(df_full['Pipeline_Total'].sum())}\n",
        "   - Mean per Image (Claude): {df_full['Claude_Total'].mean():.2f}\n",
        "   - Mean per Image (Pipeline): {df_full['Pipeline_Total'].mean():.2f}\n",
        "\n",
        "3. DEMOGRAPHICS (Claude MLLM)\n",
        "   - Adults Detected: {int(df_full['Claude_Adult'].sum())}\n",
        "   - Children Detected: {int(df_full['Claude_Child'].sum())}\n",
        "   - Adult/Child Ratio: {df_full['Claude_Adult'].sum() / max(df_full['Claude_Child'].sum(), 1):.2f}:1\n",
        "\n",
        "4. ACTIVITY DETECTION (Claude MLLM Only)\n",
        "   - Bicycles: {int(df_full['Claude_Bike'].sum())}\n",
        "   - Dogs: {int(df_full['Claude_Dog'].sum())}\n",
        "   - Backpacks: {int(df_full['Claude_Backpack'].sum())}\n",
        "   - Vehicles (Cars/Moto/ATV): {int(df_full['Claude_Car'].sum() + df_full['Claude_Motorcycle'].sum() + df_full['Claude_ATV'].sum())}\n",
        "\n",
        "5. SITES ANALYZED\n",
        "   {' | '.join([f'{site}' for site in sorted(df_full['Site'].unique())])}\n",
        "\n",
        "RECOMMENDATIONS\n",
        "----------------\n",
        "- Use Claude MLLM for comprehensive activity analysis\n",
        "- Use Pipeline Only for fast, cost-effective human counting\n",
        "- Both methods show strong agreement on detection patterns\n",
        "- Method choice depends on accuracy vs cost requirements\n",
        "\n",
        "GENERATED OUTPUTS (saved to Google Drive)\n",
        "------------------------------------------\n",
        "Tables:\n",
        "  - Table_Site_Characteristics.csv\n",
        "  - Table_Activity_Summary.csv\n",
        "  - Table_Detection_Sensitivity.csv\n",
        "  - Table_Overall_Summary.csv\n",
        "\n",
        "Figures:\n",
        "  - 01_Method_Agreement_Comparison.png\n",
        "  - 02_Demographics_Comparison.png\n",
        "  - 03_Spider_Plot_Site_Comparison.png\n",
        "  - 04_Activity_Detection_by_Site.png\n",
        "  - 05_Detection_Sensitivity.png\n",
        "\n",
        "Location: {OUTPUT_FOLDER}\n",
        "\n",
        "================================================================================\n",
        "Report generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
        "================================================================================\n",
        "\"\"\"\n",
        "    \n",
        "    print(report)\n",
        "    \n",
        "    # Save report to Google Drive\n",
        "    output_path = os.path.join(OUTPUT_FOLDER, 'Analysis_Report.txt')\n",
        "    with open(output_path, 'w') as f:\n",
        "        f.write(report)\n",
        "    print(f'‚úì Saved: {output_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary - All Files Saved to Google Drive!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('‚úÖ ANALYSIS COMPLETE!')\n",
        "print('='*80)\n",
        "print(f'\\nAll results saved to Google Drive:')\n",
        "print(f'üìÅ Folder: {OUTPUT_FOLDER}')\n",
        "print(f'\\n‚úì 4 CSV tables with detailed metrics')\n",
        "print(f'‚úì 5 publication-quality PNG figures')\n",
        "print(f'‚úì Text report with key findings')\n",
        "print(f'\\nüì• To download:')\n",
        "print(f'   1. Open Google Drive: drive.google.com')\n",
        "print(f'   2. Navigate to: {OUTPUT_FOLDER}')\n",
        "print(f'   3. Download CSV and PNG files')\n",
        "print(f'\\n‚ú® Ready to use in publications or presentations!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook Complete! ‚úÖ\n",
        "\n",
        "This analysis notebook:\n",
        "1. ‚úÖ Loads results from both pipelines\n",
        "2. ‚úÖ Compares method agreement\n",
        "3. ‚úÖ Analyzes demographics\n",
        "4. ‚úÖ Shows site characteristics\n",
        "5. ‚úÖ Creates spider/radar plots\n",
        "6. ‚úÖ Generates summary tables\n",
        "7. ‚úÖ **Saves everything to Google Drive**\n",
        "\n",
        "**No more download issues!** Everything is automatically saved to your Google Drive for easy access."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
